{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f20ef00-7648-4f74-bf74-438b9c4825ed",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "838ee49b-be74-4230-9393-d7edb4579ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Reading ./data/full_simplified_apple.ndjson... Completed\n",
      "Reading ./data/full_simplified_banana.ndjson... Completed\n",
      "Reading ./data/full_simplified_blueberry.ndjson... Completed\n",
      "Reading ./data/full_simplified_watermelon.ndjson... Completed\n",
      "              word countrycode                        timestamp  recognized  \\\n",
      "0            apple          US 2017-03-10 22:17:57.574660+00:00       False   \n",
      "1            apple          RU 2017-03-08 06:29:44.162820+00:00        True   \n",
      "2            apple          GB 2017-03-10 12:41:33.390630+00:00        True   \n",
      "3            apple          US 2017-03-16 18:01:54.559040+00:00        True   \n",
      "4            apple          TH 2017-03-29 14:35:17.694720+00:00        True   \n",
      "...            ...         ...                              ...         ...   \n",
      "713470  watermelon          TH 2017-03-26 18:10:18.156470+00:00        True   \n",
      "713471  watermelon          HU 2017-03-05 15:13:55.686980+00:00        True   \n",
      "713472  watermelon          GB 2017-01-28 19:15:54.067510+00:00        True   \n",
      "713473  watermelon          CA 2017-03-05 18:01:18.449470+00:00        True   \n",
      "713474  watermelon          US 2017-03-24 04:16:28.828370+00:00        True   \n",
      "\n",
      "                  key_id                                            drawing  \n",
      "0       6420579601088512  [[[255, 255], [0, 0]], [[255, 255], [0, 0]], [...  \n",
      "1       4986110117675008  [[[95, 79, 68, 31, 17, 9, 1, 0, 4, 54, 103, 13...  \n",
      "2       6489082920173568  [[[121, 107, 45, 17, 1, 0, 4, 21, 58, 118, 173...  \n",
      "3       4587619411296256  [[[104, 80, 54, 28, 11, 0, 1, 8, 20, 51, 90, 1...  \n",
      "4       5198601426829312  [[[85, 76, 61, 45, 34, 10, 4, 0, 4, 30, 58, 87...  \n",
      "...                  ...                                                ...  \n",
      "713470  6296408959221760  [[[10, 6, 1, 1, 43, 55, 64, 86, 113, 157, 173,...  \n",
      "713471  4783636635189248  [[[2, 5, 10, 24, 40, 55, 104, 129, 166, 211, 2...  \n",
      "713472  4800063815548928  [[[92, 44, 28, 13, 2, 0, 7, 16, 36, 62, 127, 1...  \n",
      "713473  5362428038610944  [[[60, 90, 123, 183], [5, 50, 109, 187]], [[48...  \n",
      "713474  5878535619084288  [[[241, 244, 235, 216, 157, 126, 77, 50, 14, 1...  \n",
      "\n",
      "[713475 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train and testing model\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_ndjson_to_df(file_names, print_progress=False):\n",
    "    \"\"\"\n",
    "    Load one or more ndjson files into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        file_names (list or str): A list of ndjson file names or a single file name.\n",
    "        print_progress: if True, prints debug messages that shows the progress\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the data from the ndjson file(s).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create an empty DataFrame to store the combined data\n",
    "        combined_df = pd.DataFrame()\n",
    "\n",
    "        # Check if file_names is a list or a single string\n",
    "        if isinstance(file_names, list):\n",
    "            files = file_names\n",
    "        else:\n",
    "            files = [file_names]\n",
    "\n",
    "        # Iterate over the list of file names\n",
    "        for file_name in files:\n",
    "            # Read the ndjson file into a DataFrame\n",
    "            if (print_progress):\n",
    "                print(f\"Reading {file_name}...\", end=\" \")\n",
    "            df = pd.read_json(file_name, lines=True, orient='records')\n",
    "\n",
    "            # Concatenate the DataFrame with the combined DataFrame\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "            if (print_progress):\n",
    "                print(\"Completed\")\n",
    "\n",
    "        return combined_df\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File '{e.filename}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "data_files = [\"./data/full_simplified_apple.ndjson\",\n",
    "                \"./data/full_simplified_banana.ndjson\",\n",
    "                \"./data/full_simplified_blueberry.ndjson\",\n",
    "                \"./data/full_simplified_watermelon.ndjson\",]\n",
    "print(\"Loading data...\")\n",
    "df = load_ndjson_to_df(data_files, print_progress=True)\n",
    "print(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be2181-c119-4282-bd1c-63a39daad632",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "736bdd20-8e5a-4c42-923a-5dbbb277c1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "                                                  drawing  fruit_apple  \\\n",
      "1       [[[95, 79, 68, 31, 17, 9, 1, 0, 4, 54, 103, 13...         True   \n",
      "2       [[[121, 107, 45, 17, 1, 0, 4, 21, 58, 118, 173...         True   \n",
      "3       [[[104, 80, 54, 28, 11, 0, 1, 8, 20, 51, 90, 1...         True   \n",
      "4       [[[85, 76, 61, 45, 34, 10, 4, 0, 4, 30, 58, 87...         True   \n",
      "5       [[[184, 160, 135, 100, 50, 14, 4, 0, 27, 50, 7...         True   \n",
      "...                                                   ...          ...   \n",
      "713470  [[[10, 6, 1, 1, 43, 55, 64, 86, 113, 157, 173,...        False   \n",
      "713471  [[[2, 5, 10, 24, 40, 55, 104, 129, 166, 211, 2...        False   \n",
      "713472  [[[92, 44, 28, 13, 2, 0, 7, 16, 36, 62, 127, 1...        False   \n",
      "713473  [[[60, 90, 123, 183], [5, 50, 109, 187]], [[48...        False   \n",
      "713474  [[[241, 244, 235, 216, 157, 126, 77, 50, 14, 1...        False   \n",
      "\n",
      "        fruit_banana  fruit_blueberry  fruit_watermelon  \n",
      "1              False            False             False  \n",
      "2              False            False             False  \n",
      "3              False            False             False  \n",
      "4              False            False             False  \n",
      "5              False            False             False  \n",
      "...              ...              ...               ...  \n",
      "713470         False            False              True  \n",
      "713471         False            False              True  \n",
      "713472         False            False              True  \n",
      "713473         False            False              True  \n",
      "713474         False            False              True  \n",
      "\n",
      "[662651 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing data...\")\n",
    "\n",
    "def clean_ndjson_data(df):\n",
    "    \"\"\"\n",
    "    Clean up the ndjson data by removing metadata columns and filtering out unrecognized\n",
    "    data\n",
    "    \n",
    "    Metadata columns removed: \"countrycode\", \"timestamp\", and \"key_id\" columns.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame containing the ndjson data.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: A new DataFrame with the specified columns removed.\n",
    "    \"\"\"\n",
    "    # Drop the specified columns\n",
    "    cleaned_df = df[df['recognized'] == True]\n",
    "    cleaned_df = cleaned_df.drop(columns=[\"countrycode\", \"timestamp\", \"key_id\", \"recognized\"])\n",
    "\n",
    "    return cleaned_df\n",
    "\n",
    "cleaned_df = clean_ndjson_data(df)\n",
    "# One-hot encode \"word\"\n",
    "cleaned_df = pd.get_dummies(cleaned_df, columns=[\"word\"], prefix=[\"fruit\"])\n",
    "print(cleaned_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae775475-63ba-4005-93b5-0720d0c47343",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f241443-a5ef-468a-8fd8-869c6bca1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Load dataset\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Preprocess data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define create_model function for KerasClassifier\n",
    "def create_model(num_layers=1, num_neurons=64, activation='relu', dropout_rate=0.0, momentum=0.9):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_neurons, input_dim=X_scaled.shape[1], activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(Dense(num_neurons, activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    optimizer = SGD(learning_rate=0.01, momentum=momentum)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define parameters grid for grid search\n",
    "param_grid = {\n",
    "    'num_layers': [3],\n",
    "    'num_neurons': [32, 64],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'dropout_rate': [0.2, 0.5],\n",
    "    'momentum': [0.5, 0.9]\n",
    "}\n",
    "\n",
    "# Create KerasClassifier wrapper for scikit-learn\n",
    "model = KerasClassifier(build_fn=create_model, epochs=10, batch_size=32)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, scoring='accuracy')\n",
    "grid_result = grid_search.fit(X_scaled, y)\n",
    "\n",
    "# Print results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, std, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
